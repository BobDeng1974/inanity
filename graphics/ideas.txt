Сначала создаётся объект Device. Он олицетворяет реальное графическое устройство (видеокарту), и имеет методы для создания ресурсов видеокарты (текстур, различных буферов и так далее). Затем Device создаёт объект Presenter, олицетворяющий, грубо говоря, область вывода (а в DX11 - SwapChain). Он создаётся для указанного монитора, и/или для указанного окна. Каждый Presenter имеет свою пару буферов для вывода (первичный и вторичный). Теоретически, для одного Device может быть несколько Presenter'ов, и они будут разделять ресурсы видеокарты (а куда они денутся), но это, конечно, надо протестировать.
Также класс окна Window теперь не принадлежит графической подсистеме, так как окно не обязательно означает графику и шейдеры. Окно используется и для простых вещей, тем более что на разных платформах на окна навешены ещё и "неправильные" обязанности, такие как обработка ввода, или получение сообщений об общесистемных событиях.
Окно может создавать Output - область вывода. Вот эта штука уже принадлежит графике, и именно с ней работает Presenter.
По новой стратегии, классы конкретной графической подсистемы, такой, как DX или GL, должны быть как можно более примитивными. Более высокоуровневые классы должны быть уже независимыми от графической платформы.

DirectX 11
DxDevice отвечает за ID3D11Device.
DxPresenter отвечает за IDXGISwapChain и IDXGIOutput. Пока IDXGIOutput никак нельзя задать вручную, то есть он будет всегда один. Также IDXGIOutput вроде как нельзя включить в Win32Output, так как он должен работать и с OpenGL.

OpenGL
GlDevice по сути только хранит имя устройства (в Windows). Из-за ущербной архитектуры OpenGL получается всё не очень красиво. Устройство, вероятно, будет стараться заставлять контексты расшаривать ресурсы между собой.
Полезная ссылка насчёт нескольких контекстов:
http://www.opengl.org/discussion_boards/showthread.php/164467-Any-reason-not-to-share-GL-context-s-resources
Несколько планов действий.
- Использовать один контекст на устройство. Только в конце рисования кадра (при рисовании на вторичный буфер), выполнять привязку к нужному HDC.
- Использовать один FBO и один контекст на устройство. При рисовании на вторичный буфер просто привязывать к нему рендербуфер окна. Если так можно.
- Создать один невидимый контекст, и с помощью него создавать ресурсы. А каждый Presenter будет иметь свой контекст, расшаривающий ресурсы с невидимым контекстом.

Кстати, вместо GLEW есть ещё GLEE, возможно, оно чуть удобнее.

Backbuffer по-видимому, можно прицеплять только одним.

Кстати, нужно не забывать, чтобы объекты OpenGL удерживали ссылки на родительские объекты, иначе устройство может закрыться преждевременно, и прибьёт все объекты OpenGL.

Семплеры. Так как в OpenGL настройки сэмплирования хранятся в самой текстуре, а не в отдельном sampler state, как в DX10/11, то придётся делать другую систему. Таки нет, в OpenGL семплеры - это отдельные вещи :) Но всё равно не совсем так, как в DX.
В OpenGL: есть texture units, к каждому присоединяется текстура, и можно ещё присоединить семплер. Присоединённый семплер перекрывает настройки семплирования, которые есть в текстуре. А уже texture unit index указывается для GLSL-переменной.
Таким образом, на каждую пару текстура-семплер всё равно тратится texture unit index. В отличие от DirectX, где текстуры и семплеры указываются отдельно, и связываются уже в шейдере.
То есть, в нашей абстрактной системе делаем, как в OpenGL.

Связь геометрия - вершинный шейдер.
В DirectX тупая система. Делается входная разметка (InputLayout), которая хранит имена семантик, и пытается их сопоставить с именами семантик, заданными в шейдере.

Язык шейдеров.
- Константы задаются конструкцией ConstFloat или ConstInt.
- Конструктор векторов - специальные функции.

Привязка атрибутов (вершин) к шейдеру, не обязательно нужна для всех пар разметка-шейдер. Если вершинные шейдеры имеют идентичные входные структуры, то можно использовать одну разметку.

Row-major - это порядок, когда первый индекс - номер строки. Как в C++ массивы. Для матриц означает, что в регистрах строки. Правильное умножение:
если row-major: mul(mx, vec)
если column-major: mul(vec, mx)
Матричные функции D3DX рассчитаны на column-major. OpenGL в основном тоже. А C++ на row-major. Пичалька. Вывод - делаем транспозицию перед передачей в шейдер.


В программируемый pipeline передаются следующие данные:
- Вершинный буфер.
Привязка вершинного буфера к переменным/регистрам шейдера делается семантиками (в DirectX) или вручную по location'ам (в OpenGL). В первом случае это DxIntenalInputLayout, во втором - GlInternalAttributeBinding, но суть одна - вершинный буфер может иметь любой формат, перестановка и привязка к регистрам всё равно делается каждый раз.
- Индексный буфер.
Никаких проблем не предвидится.
- Uniform-буферы (константные буферы).
http://www.opengl.org/wiki/Uniform_Buffer_Object
http://www.opengl.org/wiki/GLSL_Interface_Block
Uniform-буферы привязываются к uniform-слотам. Порядок и формат данных в uniform-буфере должен точно совпадать с порядком и форматом в шейдере (если использовать memory layout = std140). В OpenGL можно также использовать memory layout = shared, чтобы получить оптимальную упаковку данных. А DirectX забивает на всё это, и у него просто есть правила упаковки данных (проще говоря, у него есть только std140). Ещё OpenGL умеет транспонировать матрицы перед использованием, но это по идее не надо использовать, да и DirectX не умеет. Использование layout=shared усложняет дело, так как нам нужно вручную выбрать какой-то шейдер, и получить для него layout, а затем использовать его для него и похожих шейдеров. Вывод пока - использовать std140 в OpenGL, в DirectX он и так есть, и сделать промежуточный слой, преобразующий данные из структуры C++ в формат буфера (как минимум, для транспонирования матриц). Значит, нужны объекты UniformData, и UniformBinding. Вопрос - как различать переменные в коде? По именам? Ну да, проще всего по именам. Шейдер, генерирующий 
- Текстуры и семплеры.